{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timotos/anaconda3/envs/bpg_env/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/timotos/anaconda3/envs/bpg_env/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.transforms import v2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "# import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = './data/Covid19-dataset/train'\n",
    "TEST_DIR = './data/Covid19-dataset/test'\n",
    "\n",
    "def load_data(data_path):\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "\n",
    "    folds = os.listdir(data_path)\n",
    "    for fold in folds:\n",
    "        foldpath = os.path.join(data_path, fold)\n",
    "        filelist = os.listdir(foldpath)\n",
    "        for file in filelist:\n",
    "            fpath = os.path.join(foldpath, file)\n",
    "            filepaths.append(fpath)\n",
    "            labels.append(fold)\n",
    "\n",
    "    # Concatenate data paths with labels into one dataframe\n",
    "    Fseries = pd.Series(filepaths, name= 'filepaths')\n",
    "    Lseries = pd.Series(labels, name='labels')\n",
    "    df = pd.concat([Fseries, Lseries], axis= 1)\n",
    "    return df\n",
    "\n",
    "MAPPING = {'Normal':0,\n",
    "           'Viral Pneumonia': 1,\n",
    "           'Covid':2}\n",
    "\n",
    "train_data = load_data(TRAIN_DIR)\n",
    "# val_data = train_data.iloc[-int(len(train_data) * 0.3):-1, :]\n",
    "test_data = load_data(TEST_DIR)\n",
    "train_data.iloc[:,1] = train_data.iloc[:,1].apply(lambda x: MAPPING[x])\n",
    "test_data.iloc[:,1] = test_data.iloc[:,1].apply(lambda x: MAPPING[x])\n",
    "# data = pd.concat([train_data, test_data])\n",
    "\n",
    "# data['true_label'] = data['labels'].apply(lambda x: MAPPING[x])\n",
    "# train_data = train_data[train_data.labels != 'Viral Pneumonia']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.data_frame = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data_frame.iloc[idx, 0]\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label = self.data_frame.iloc[idx, 1]\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "\n",
    "# Define the transformations\n",
    "data_transforms = {\n",
    "    'train': v2.Compose([\n",
    "        v2.Resize((224, 224)),\n",
    "        v2.ToTensor(),\n",
    "        # v2.RandomHorizontalFlip(p=0.5),\n",
    "        # transforms.Normalize(mean=0, std=1)\n",
    "        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': v2.Compose([\n",
    "        v2.Resize((224, 224)),\n",
    "        v2.ToTensor(),\n",
    "        # transforms.Normalize(mean=0, std=1)\n",
    "        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "train_dataset = CustomImageDataset(train_data, transform=data_transforms['train'])\n",
    "val_dataset = CustomImageDataset(test_data, transform=data_transforms['val'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "dataloaders = {'train': train_loader, 'val': val_loader}\n",
    "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.densenet121(pretrained=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "# Modify the model for 3 classes\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier = nn.Linear(num_ftrs, 3)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "num_epochs = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6254 Acc: 0.7610\n",
      "val Loss: 0.6815 Acc: 0.6667\n",
      "\n",
      "train Loss: 0.5519 Acc: 0.8048\n",
      "val Loss: 2.1882 Acc: 0.4242\n",
      "\n",
      "train Loss: 0.3731 Acc: 0.8685\n",
      "val Loss: 0.4766 Acc: 0.7727\n",
      "\n",
      "train Loss: 0.4256 Acc: 0.8048\n",
      "val Loss: 2.7340 Acc: 0.5758\n",
      "\n",
      "train Loss: 0.2588 Acc: 0.9084\n",
      "val Loss: 0.1648 Acc: 0.9545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            # labels = labels.to(device).float().unsqueeze(1)\n",
    "            labels = labels.to(device).long()\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "        \n",
    "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "    \n",
    "    print()\n",
    "\n",
    "# # Save the model\n",
    "torch.save(model.state_dict(), 'covid_classifier.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model loading and prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timotos/anaconda3/envs/bpg_env/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/timotos/anaconda3/envs/bpg_env/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "def load_model(model_path, device):\n",
    "    model = models.densenet121(pretrained=True)\n",
    "    num_ftrs = model.classifier.in_features\n",
    "    model.classifier = nn.Linear(num_ftrs, 3)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def predict(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "         \n",
    "            all_labels.extend(preds.numpy())\n",
    "    \n",
    "    return all_labels\n",
    "\n",
    "model_path = 'covid_classifier.pth'\n",
    "model = load_model(model_path, device)\n",
    "\n",
    "\n",
    "test_dataloader = DataLoader(val_dataset, batch_size=5, shuffle=False)\n",
    "\n",
    "test_labels = predict(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['forecasted_label'] = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>labels</th>\n",
       "      <th>fc</th>\n",
       "      <th>forecasted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>./data/Covid19-dataset/test/Normal/0116.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>./data/Covid19-dataset/test/Normal/0118.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>./data/Covid19-dataset/test/Normal/0112.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       filepaths labels  fc  forecasted_label\n",
       "27  ./data/Covid19-dataset/test/Normal/0116.jpeg      0   1                 1\n",
       "34  ./data/Covid19-dataset/test/Normal/0118.jpeg      0   1                 1\n",
       "39  ./data/Covid19-dataset/test/Normal/0112.jpeg      0   1                 1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[test_data.labels != test_data.forecasted_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('output'):\n",
    "    os.makedirs('output')\n",
    "\n",
    "\n",
    "test_data.to_csv('output/predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bpg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
